{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pats\n",
    "from unidecode import unidecode\n",
    "import sys, os, re\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse(pdf: fitz.Document) -> (str, dict):\n",
    "    s, idx, d = [], 0, {}\n",
    "    for page in pdf.pages():\n",
    "        tdict = page.get_text(\n",
    "            'rawdict',\n",
    "            flags=fitz.TEXTFLAGS_RAWDICT & ~fitz.TEXT_PRESERVE_IMAGES\n",
    "        )\n",
    "        for block in tdict['blocks']:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    for char in span['chars']:\n",
    "                        d[idx] = (page.number, *char['bbox'], span)\n",
    "                        c = char['c']\n",
    "                        uc = unidecode(c)\n",
    "                        s.append(uc)\n",
    "                        idx += len(uc)\n",
    "                prev_span = line['spans'][-1]\n",
    "                prev_char = prev_span['chars'][-1]\n",
    "                if prev_char['c'] == '-':\n",
    "                    for i in range(-1, -50, -1):\n",
    "                        if s[i] == ' ':\n",
    "                            s[i] = '\\n'\n",
    "                            break\n",
    "                    s.pop()\n",
    "                    idx -= 1\n",
    "                else:\n",
    "                    d[idx] = (page.number, *prev_char['bbox'], prev_span)\n",
    "                    s.append('\\n')\n",
    "                    idx += 1\n",
    "    return ''.join(s), d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf = fitz.open('apa-nolinks.pdf')\n",
    "pdf = fitz.open('apa-std-1.pdf')\n",
    "pdf_text, char_info = parse(pdf)\n",
    "with open('out.txt', 'wb') as f:\n",
    "    f.write(pdf_text.encode('utf-8', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = pats.patterns['ieee']\n",
    "\n",
    "# Find reference list starting point\n",
    "m_ref_list = list(re.finditer(pats.start_of_ref_list, pdf_text, re.M))\n",
    "assert(len(m_ref_list) == 1)\n",
    "m_ref_list = m_ref_list[0]\n",
    "\n",
    "# Find all reference destinations\n",
    "dst = {}\n",
    "for m_dst in re.finditer(pat['dst'], pdf_text[m_ref_list.end():], re.M | re.S):\n",
    "    pg, x0, y0, x1, y1, *_ = char_info[m_dst.start() + m_ref_list.end()]\n",
    "    key = m_dst.groups()\n",
    "    if key in dst.keys():\n",
    "        print(f'Warning: duplicate reference key {key}')\n",
    "    else:\n",
    "        dst[key] = (pg, x0, y0)\n",
    "        #pdf[pg].add_highlight_annot([x0, y0, x1, y1])\n",
    "\n",
    "if pat['alt-ref']:\n",
    "    for m in re.finditer(pat['alt-ref'], pdf_text, re.M | re.S):\n",
    "        start, end = m.span()\n",
    "\n",
    "        prev_y0 = char_info[start][2]\n",
    "        segments = [list(char_info[start][0:5])]\n",
    "        for i in range(start, end):\n",
    "            pg, x0, y0, x1, y1, s = char_info[i]\n",
    "            if y0 == prev_y0:\n",
    "                segments[-1][3] = x1\n",
    "            else:\n",
    "                segments.append(list(char_info[i][0:5]))\n",
    "                prev_y0 = y0\n",
    "            \n",
    "        d_pg, d_x, d_y = dst.get(m.groups(), [None]*3)\n",
    "\n",
    "        for s in segments:\n",
    "            page = pdf[s[0]]\n",
    "            h = page.add_highlight_annot(s[1:5])\n",
    "            if not d_pg:\n",
    "                h.set_colors({'stroke': (1,0,0), 'fill': None})\n",
    "                h.update()\n",
    "            if d_pg:\n",
    "                page.insert_link({\n",
    "                    'kind': fitz.LINK_GOTO,\n",
    "                    'from': fitz.Rect(*s[1:5]), \n",
    "                    'page': d_pg,\n",
    "                    'to': fitz.Point(d_x, d_y),\n",
    "                })\n",
    "\n",
    "# Create links for references\n",
    "for m_refs in re.finditer(pat['refs'], pdf_text, re.M | re.S):\n",
    "    for m in re.finditer(pat['ref'], m_refs.group()):\n",
    "\n",
    "        start, end = m.span()[0] + m_refs.start(), m.span()[1] + m_refs.start()\n",
    "\n",
    "        prev_y0 = char_info[start][2]\n",
    "        segments = [list(char_info[start][0:5])]\n",
    "        for i in range(start, end):\n",
    "            pg, x0, y0, x1, y1, s = char_info[i]\n",
    "            if y0 == prev_y0:\n",
    "                segments[-1][3] = x1\n",
    "            else:\n",
    "                segments.append(list(char_info[i][0:5]))\n",
    "                prev_y0 = y0\n",
    "            \n",
    "        d_pg, d_x, d_y = dst.get(m.groups(), [None]*3)\n",
    "\n",
    "        for s in segments:\n",
    "            page = pdf[s[0]]\n",
    "            h = page.add_highlight_annot(s[1:5])\n",
    "            if not d_pg:\n",
    "                h.set_colors({'stroke': (1,0,0), 'fill': None})\n",
    "                h.update()\n",
    "            if d_pg:\n",
    "                page.insert_link({\n",
    "                    'kind': fitz.LINK_GOTO,\n",
    "                    'from': fitz.Rect(*s[1:5]), \n",
    "                    'page': d_pg,\n",
    "                    'to': fitz.Point(d_x, d_y),\n",
    "                })\n",
    "\n",
    "pdf.save('out.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_num = pdf[1]\n",
    "tdict = pg_num.get_text('dict', flags=fitz.TEXTFLAGS_DICT & ~fitz.TEXT_PRESERVE_IMAGES)\n",
    "with open('out.py', 'w') as f:\n",
    "    pprint(tdict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Li', None, '2022b')\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "For example, Li et al. (2022b) provide a de?nition by decomposing\n",
    "the adaptation cost into sample-ef?ciency and parameter-ef?ciency.\n",
    "\"\"\"\n",
    "\n",
    "for m in re.finditer(pats.apa['alt-ref'], s, re.DOTALL | re.MULTILINE):\n",
    "    print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('L?uddecke', 'Ecker', '2022')\n",
      "('van den Oord', None, '2017')\n",
      "('Xu', None, '2015')\n",
      "('Chen', 'Luo', '2020')\n",
      "('Chen', None, '2020d')\n",
      "('Lin', None, '2004')\n",
      "('Abu-El-Haija', None, '2016')\n",
      "('Agarwal', None, '2020')\n",
      "('Karpathy', 'Fei-Fei', '2015')\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\"\n",
    "L?uddecke, T. and Ecker, A. (2022). Image segmentation using text and image prompts. In CVPR.\n",
    "van den Oord, A., Vinyals, O., and Kavukcuoglu, K. (2017). Neural discrete representation learning.\n",
    "In NeurIPS.\n",
    "Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R., and Bengio, Y. (2015).\n",
    "Show, attend and tell: Neural image caption generation with visual attention. In ICML.\n",
    "Chen, T. and Luo, J. (2020). Expressing objects just like words: Recurrent visual embedding for\n",
    "image-text matching. In AAAI.\n",
    "Chen, Y.-C., Li, L., Yu, L., El Kholy, A., Ahmed, F., Gan, Z., Cheng, Y., and Liu, J. (2020d).\n",
    "UNITER: Universal image-text representation learning. In ECCV.\n",
    "Lin, C.-Y. (2004). Rouge: A package for automatic evaluation of summaries. In Text summarization\n",
    "branches out.\n",
    "Abu-El-Haija, S., Kothari, N., Lee, J., Natsev, P., Toderici, G., Varadarajan, B., and Vijaya-\n",
    "narasimhan, S. (2016). Youtube-8m: A large-scale video classiÔ¨Åcation benchmark. arXiv preprint\n",
    "arXiv:1609.08675.\n",
    "Agarwal, V., Shetty, R., and Fritz, M. (2020). Towards causal vqa: Revealing and reducing spurious\n",
    "correlations by invariant and covariant semantic editing. In CVPR.\n",
    "Karpathy, A. and Fei-Fei, L. (2015). Deep visual-semantic alignments for generating image descrip-\n",
    "tions. In CVPR.\n",
    "\"\"\"\n",
    "\n",
    "#print(pats.apa['dst'])\n",
    "\n",
    "for m in re.finditer(pats.apa['dst'], s, re.DOTALL | re.MULTILINE):\n",
    "    print(m.groups())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
